{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from numpy.random import seed\n",
    "#seed(1)\n",
    "#from tensorflow import set_random_seed\n",
    "#set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'heart-disease-svm-and-logistic-Copy1.ipynb', 'heart-disease-svm-and-logistic.ipynb', 'heart.csv', 'heart2.csv', 'Orignal.ipynb']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noor\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../Heart Disease Detection\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1=pd.read_csv('../Heart Disease Detection/heart.csv')\n",
    "d1\n",
    "d1[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "13262c70f2c7be886e160433e04a25dffeac51aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "b25b95011213a3ff635abd7882868167ffb67762"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=d1.drop('target',axis=1)\n",
    "y=d1['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a2cf1d7b9844ea5e684dc3fbc446d72f762da39b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr=LinearRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "daec4d6f640216e8a9570500dc75528ded369406"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263883193613788"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "1fa76fef5acd184530e38ba9fb25150c613cf0a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_svc = LinearSVC(penalty='l1',dual=False,tol=1e-3)\n",
    "clf_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "350fb375c28bbe7151aa7feb2b660fecfe2a9276"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8502202643171806"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "5b7099abcfb7c9ffc6a0c5f30d9ae7fd27cc4f86"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "fa7353612a40743a0130349e881077482fea66c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "c0d4332dc288b49bf2b10f17b9d103afab3f169b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8289473684210527"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    #keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(13, activation=tf.nn.relu),\n",
    "    #keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(26, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 106us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 106us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 123us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 106us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 106us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 106us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 9.0664 - acc: 0.437 - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 41/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 42/100\n",
      "227/227 [==============================] - 0s 106us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 43/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 44/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 45/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 46/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 47/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 48/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 49/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 50/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 51/100\n",
      "227/227 [==============================] - 0s 106us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 52/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 53/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 54/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 55/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 56/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 57/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 58/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 59/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 60/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 61/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 62/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 63/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 64/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 65/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 66/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 67/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 68/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 69/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 70/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 71/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 72/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 73/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 74/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 75/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 76/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 77/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 78/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 79/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 80/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 81/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 82/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 83/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 84/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 85/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 86/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 87/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 88/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 89/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 90/100\n",
      "227/227 [==============================] - 0s 106us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 91/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 92/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 93/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 94/100\n",
      "227/227 [==============================] - 0s 106us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 95/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 96/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 97/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 98/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 99/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 8.6626 - acc: 0.4626\n",
      "Epoch 100/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 8.6626 - acc: 0.4626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x9ca6912f28>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.values, y_train.values, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 895us/step\n",
      "Test accuracy: 0.4342105263157895\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test.values, y_test.values )\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 1.3638840e-16]\n",
      " [1.0000000e+00 3.8299364e-18]\n",
      " [1.0000000e+00 3.6205149e-17]\n",
      " [1.0000000e+00 1.6420279e-18]\n",
      " [1.0000000e+00 2.4096125e-17]\n",
      " [1.0000000e+00 1.7299912e-12]\n",
      " [1.0000000e+00 3.9515266e-18]\n",
      " [1.0000000e+00 1.5844896e-15]\n",
      " [1.0000000e+00 1.3412251e-14]\n",
      " [1.0000000e+00 1.4042687e-13]\n",
      " [1.0000000e+00 1.0687942e-17]\n",
      " [1.0000000e+00 8.7441424e-16]\n",
      " [1.0000000e+00 8.0197534e-18]\n",
      " [1.0000000e+00 1.3240414e-16]\n",
      " [1.0000000e+00 9.5747366e-16]\n",
      " [1.0000000e+00 1.9721012e-16]\n",
      " [1.0000000e+00 2.9767004e-17]\n",
      " [1.0000000e+00 2.8512793e-11]\n",
      " [1.0000000e+00 8.8159851e-16]]\n"
     ]
    }
   ],
   "source": [
    "predictions_single = model.predict(X_test[1:20])\n",
    "print(predictions_single)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
